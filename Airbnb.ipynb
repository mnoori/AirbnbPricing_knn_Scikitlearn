{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_response_rate                  92%\n",
      "host_acceptance_rate                91%\n",
      "host_listings_count                  26\n",
      "accommodates                          4\n",
      "room_type               Entire home/apt\n",
      "bedrooms                              1\n",
      "bathrooms                             1\n",
      "beds                                  2\n",
      "price                           $160.00\n",
      "cleaning_fee                    $115.00\n",
      "security_deposit                $100.00\n",
      "minimum_nights                        1\n",
      "maximum_nights                     1125\n",
      "number_of_reviews                     0\n",
      "latitude                          38.89\n",
      "longitude                      -77.0028\n",
      "city                         Washington\n",
      "zipcode                           20003\n",
      "state                                DC\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dc_listings = pd.read_csv('dc_airbnb.csv')\n",
    "print(dc_listings.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.965628356605684\n",
      "11970.823931256706\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "dc_listings['price']=dc_listings['price'].apply(str)\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '') #remove commans\n",
    "stripped_dollars = stripped_commas.str.replace('$', '') #remove dollar sign\n",
    "dc_listings['price'] = stripped_dollars.astype('float') #convert to float\n",
    "dc_listings=dc_listings.loc[np.random.permutation(len(dc_listings))] #randomply changes the order of rows\n",
    "train_df = dc_listings.iloc[0:2792]\n",
    "test_df = dc_listings.iloc[2792:]\n",
    "\n",
    "def predict_price(new_listing):\n",
    "    ## DataFrame.copy() performs a deep copy\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['accommodates'].apply(lambda x: np.abs(x - new_listing)) #calculates the disatnce...\n",
    "    #...of our listing with accommodates column in the dataset\n",
    "    temp_df = temp_df.sort_values('distance') #sorts by distance\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price'] \n",
    "    predicted_price = nearest_neighbor_prices.mean() #gets the average of price among first five with least distances\n",
    "    return(predicted_price)\n",
    "\n",
    "test_df['predicted_price']=test_df['accommodates'].apply(lambda x: predict_price(x))\n",
    "\n",
    "#now let's estimate the mean absolute error\n",
    "test_df['abs_error'] = np.absolute(test_df['predicted_price'] - test_df['price'])\n",
    "mae = test_df['abs_error'].mean()\n",
    "print(mae)\n",
    "\n",
    "#However, this does not show those predicted values that are way further away from the actual values.\n",
    "#We can use Mean Squared Error instead, as it squares the magnitude of error.\n",
    "test_df['sq_error'] = (test_df['predicted_price'] - test_df['price'])**2\n",
    "mae = test_df['sq_error'].mean()\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't really say whether the calculated MSE is actually low or high. In fact, the units of this error is dollar squared, which makes it even harder to interpret intuitively. What can we do is to fit another model and measure the MSE for that model and then compare. \n",
    "\n",
    "Let's fit a model based on number of bathrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13990.16764769065\n"
     ]
    }
   ],
   "source": [
    "def predict_price(new_listing):\n",
    "    ## DataFrame.copy() performs a deep copy\n",
    "    temp_df = train_df.copy()\n",
    "    temp_df['distance'] = temp_df['bathrooms'].apply(lambda x: np.abs(x - new_listing)) #calculates the disatnce...\n",
    "    #...of our listing with bathrooms column in the dataset\n",
    "    temp_df = temp_df.sort_values('distance') #sorts by distance\n",
    "    nearest_neighbor_prices = temp_df.iloc[0:5]['price'] \n",
    "    predicted_price = nearest_neighbor_prices.mean() #gets the average of price among first five with least distances\n",
    "    return(predicted_price)\n",
    "\n",
    "test_df['predicted_price']=test_df['bathrooms'].apply(lambda x: predict_price(x))\n",
    "test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)\n",
    "mse = test_df['squared_error'].mean()\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about measuring the Root Mean Squared Error? it will be in the same units of our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118.28003909236186\n"
     ]
    }
   ],
   "source": [
    "rmse = mse ** (1/2)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\$118 of error. This is too much, considering the listings are a couple of hundred dollars. There are two ways that we can achieve that goal:\n",
    "* include more attributes\n",
    "* increase k\n",
    "Let's look at including more attributes. But first, we'd like to remove columns that are non-numerical, non-ordinal, and do not have anything to do with living space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3723 entries, 1693 to 1857\n",
      "Data columns (total 19 columns):\n",
      "host_response_rate      3289 non-null object\n",
      "host_acceptance_rate    3109 non-null object\n",
      "host_listings_count     3723 non-null int64\n",
      "accommodates            3723 non-null int64\n",
      "room_type               3723 non-null object\n",
      "bedrooms                3702 non-null float64\n",
      "bathrooms               3696 non-null float64\n",
      "beds                    3712 non-null float64\n",
      "price                   3723 non-null float64\n",
      "cleaning_fee            2335 non-null object\n",
      "security_deposit        1426 non-null object\n",
      "minimum_nights          3723 non-null int64\n",
      "maximum_nights          3723 non-null int64\n",
      "number_of_reviews       3723 non-null int64\n",
      "latitude                3723 non-null float64\n",
      "longitude               3723 non-null float64\n",
      "city                    3723 non-null object\n",
      "zipcode                 3714 non-null object\n",
      "state                   3723 non-null object\n",
      "dtypes: float64(6), int64(5), object(8)\n",
      "memory usage: 581.7+ KB\n"
     ]
    }
   ],
   "source": [
    "dc_listings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Host response rate might have something to do with the price, if we knew how to uniquely group living spaces to the hosts, we could use this information. For now, we will drop it.\n",
    "Zipcode, state, city, room_type are non numerical. Latitude and Longtitude are non-ordinal. We'll drop them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3723\n",
      "accommodates            0\n",
      "bedrooms               21\n",
      "bathrooms              27\n",
      "beds                   11\n",
      "price                   0\n",
      "cleaning_fee         1388\n",
      "security_deposit     2297\n",
      "minimum_nights          0\n",
      "maximum_nights          0\n",
      "number_of_reviews       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "drop_columns = ['room_type', 'city', 'state', 'latitude', 'longitude', 'zipcode', 'host_response_rate', 'host_acceptance_rate', 'host_listings_count']\n",
    "dc_listings_new = dc_listings.drop(drop_columns, axis=1)\n",
    "print(dc_listings_new.shape[0])\n",
    "print(dc_listings_new.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of missing values in bedrooms, bathrooms, and beds are trivial to overall observations. We can remove those rows.\n",
    "For cleaning fee and security deposit, the number of missing values are substaintial. We can't remove the rows as we will lose so much information in our dataset. Hence, we simply remove those two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc_listings_new=dc_listings_new.drop(['cleaning_fee','security_deposit'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates         0\n",
      "bedrooms             0\n",
      "bathrooms            0\n",
      "beds                 0\n",
      "price                0\n",
      "minimum_nights       0\n",
      "maximum_nights       0\n",
      "number_of_reviews    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dc_listings_new=dc_listings_new.dropna(axis=0)\n",
    "print(dc_listings_new.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2546</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>4</td>\n",
       "      <td>365</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accommodates  bedrooms  bathrooms  beds  price  minimum_nights  \\\n",
       "1693             2       1.0        1.5   1.0  140.0               2   \n",
       "2546             4       1.0        1.0   2.0  115.0               2   \n",
       "728              2       1.0        1.0   1.0  149.0               4   \n",
       "1297             3       1.0        1.0   1.0  130.0               1   \n",
       "1194             3       0.0        1.0   2.0  129.0               4   \n",
       "\n",
       "      maximum_nights  number_of_reviews  \n",
       "1693            1125                 20  \n",
       "2546              90                 59  \n",
       "728              109                  8  \n",
       "1297            1125                  7  \n",
       "1194             365                 26  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_listings_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the range of maximum nights and number of reviews are much larger than other feastures. This will lead to potential outsize effect on calculating the error. Hence, let's normalize the values. How? using standard normal distribution. why? to also account for distribution of data and at the same time, normalize it.\n",
    "\n",
    "x'=(x-mean)/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_listings = (dc_listings_new - dc_listings_new.mean())/(dc_listings_new.std())\n",
    "#but we'd like for our target value to stay the same\n",
    "normalized_listings['price'] = dc_listings_new['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting\n",
    "#### Impact of number of attributes on model accuracy\n",
    "Now let's use Scikit-learn library for model fittiing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10727.8759954\n",
      "103.575460392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor #importing the class of K nearest neighbors\n",
    "from sklearn.metrics import mean_squared_error #importing the mean squared error function\n",
    "\n",
    "train_df = normalized_listings.iloc[0:2792] #75% trainiing set\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "features = ['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews'] #selecting our first batch of columns\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean') #instatiating the class\n",
    "knn.fit(train_df[features], train_df['price']) #fit gets a matrix-like and a list-like arguments.\n",
    "predictions = knn.predict(test_df[features]) #predict takes the features of test dataset\n",
    "\n",
    "two_features_mse = mean_squared_error(test_df['price'], predictions) #takes two vectors\n",
    "two_features_rmse = two_features_mse ** (1/2)\n",
    "print(two_features_mse)\n",
    "print(two_features_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11098.9878953\n",
      "105.351734183\n"
     ]
    }
   ],
   "source": [
    "# Now let's test if we'd take all features\n",
    "\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute', metric='euclidean')\n",
    "knn.fit(train_df[features], train_df['price'])\n",
    "predictions = knn.predict(test_df[features])\n",
    "\n",
    "two_features_mse = mean_squared_error(test_df['price'], predictions)\n",
    "two_features_rmse = two_features_mse ** (1/2)\n",
    "print(two_features_mse)\n",
    "print(two_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary so far\n",
    "Adding more attributes generally decreasaes the model's error, and that is becuase the model looks for more similar observations to our case by looking at more attributes (and not just number of bedrooms per say). Also, we realized sometimes adding irrelavent attributes increases the error, so we should perform some \"feature selection\".\n",
    "\n",
    "#### Impact of k value on model accuracy (hyperparameter optimization)\n",
    "when we change the number features, we are changing the input data. Changing the k value keeps the data intact, and changes the behaviour of the model.\n",
    "\n",
    "First let's comfirm the impact of k on model accuracy using a grid search approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[119.85618515309889,\n",
       " 105.9873186653064,\n",
       " 105.36669270571518,\n",
       " 105.02973670147584,\n",
       " 105.35173418285818]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a subset of 5 values for k\n",
    "hyper_parms=list(range(5))\n",
    "hyper_parms=[x+1 for x in hyper_parms]\n",
    "\n",
    "rmse=[]\n",
    "for k in hyper_parms:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "\n",
    "    two_features_mse = mean_squared_error(test_df['price'], predictions)\n",
    "    two_features_rmse = two_features_mse ** (1/2)\n",
    "    rmse.append(two_features_rmse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error is decreasing by increase in k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[119.85618515309889,\n",
       " 105.9873186653064,\n",
       " 105.36669270571518,\n",
       " 105.02973670147584,\n",
       " 105.35173418285818,\n",
       " 103.9371345979205,\n",
       " 102.58062742175066,\n",
       " 102.05360921181081,\n",
       " 103.21788390597581,\n",
       " 101.73282392141765,\n",
       " 102.04082067278486,\n",
       " 102.00627093690758,\n",
       " 102.33205154044087,\n",
       " 102.27945894184569,\n",
       " 102.54932215107173,\n",
       " 102.05030826084452,\n",
       " 101.91312801590448,\n",
       " 101.83773326950454,\n",
       " 101.88347093405439,\n",
       " 101.89773769651515]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's create a subet of 20\n",
    "hyper_parms=[x for x in range(1,21)]\n",
    "\n",
    "rmse=[]\n",
    "for k in hyper_parms:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "    knn.fit(train_df[features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[features])\n",
    "\n",
    "    two_features_mse = mean_squared_error(test_df['price'], predictions)\n",
    "    two_features_rmse = two_features_mse ** (1/2)\n",
    "    rmse.append(two_features_rmse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x116de2908>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25264e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(hyper_parms, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, as can be seen, the optimum value for k is 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holdout validation\n",
    "So far, we've been using train/test validation. Now we'd like to use holdout method. We divide dataset in two seperate equal size sets and swap train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling the deck!\n",
    "shuffled_index = np.random.permutation(dc_listings.index)\n",
    "dc_listings = dc_listings.reindex(shuffled_index)\n",
    "\n",
    "split_one = dc_listings.iloc[0:1862] #50% of dataset\n",
    "split_two = dc_listings.iloc[1862:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.47882852165077"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one = split_one\n",
    "test_one = split_two\n",
    "train_two = split_two\n",
    "test_two = split_one\n",
    "\n",
    "model=KNeighborsRegressor()\n",
    "model.fit(train_one[[\"accommodates\"]],train_one['price'])\n",
    "test_one['predicted_price']=model.predict(test_one[['accommodates']])\n",
    "rmse_one=mean_squared_error(test_one['price'],test_one['predicted_price'])**(1/2)\n",
    "\n",
    "model.fit(train_two[[\"accommodates\"]],train_two['price'])\n",
    "test_two['predicted_price']=model.predict(test_two[['accommodates']])\n",
    "rmse_two=mean_squared_error(test_two['price'],test_two['predicted_price'])**(1/2)\n",
    "\n",
    "avg_rmse=(rmse_one+rmse_two)/2\n",
    "avg_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout validation is a subset of k-fold corss validation process. In k-fold, we break the data set in k segments and repeat the train-test process across all segments by first training the model on k-1 segments, and then testing them out on the kth segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    735\n",
       "4.0    734\n",
       "3.0    734\n",
       "2.0    734\n",
       "1.0    734\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here, we assign a fold value in a new column for each segment of dataset.\n",
    "fold=int(normalized_listings.shape[0]/5)\n",
    "for i in range(4):\n",
    "    normalized_listings.set_value(normalized_listings.index[(i*fold):((i+1)*fold)],'fold',i+1)\n",
    "\n",
    "normalized_listings.set_value(normalized_listings.index[4*fold:normalized_listings.shape[0]],'fold',5)\n",
    "normalized_listings['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error is:  108.642914877\n"
     ]
    }
   ],
   "source": [
    "features=normalized_listings.columns.tolist()\n",
    "features.remove('price')\n",
    "rmse=[]\n",
    "for fold in range(5):\n",
    "    test_df=normalized_listings[dc_listings['fold']==fold+1]\n",
    "    train_df=normalized_listings[normalized_listings['fold']!=fold+1]\n",
    "    model=KNeighborsRegressor()\n",
    "    model.fit(train_df[features],train_df['price'])\n",
    "    predictions=model.predict(test_df[features])\n",
    "    rmse.append(mean_squared_error(test_df['price'],predictions)**(1/2))\n",
    "\n",
    "print('average error is: ', np.mean(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the takeaway so far:\n",
    "* if we want to build a better k nearest neighbors model, we can use different features or alter k value.\n",
    "* to test our model performance, we can use k fold cross validation and select the proper number of folds.\n",
    "\n",
    "Next, we'd like to see how we can get advantage of Scikit learn libraries for handling corss-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.080334234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "kf=KFold(5,shuffle=True,random_state=1) #k=5, shuffles throw observations, and random seed is set to 1 for future iterations.\n",
    "knn=KNeighborsRegressor()\n",
    "\n",
    "#following function takes the estimator (here knn),tarining features, target value, scoring method, and number of folds...\n",
    "#...number of folds (cv) can be a number or an instance of class KFold.\n",
    "mses=cross_val_score(knn,normalized_listings[features],normalized_listings['price'],scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "avg_rmse=np.mean((abs(mses))**(1/2))\n",
    "print(avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the error for different amount of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 115.13480261235263,\n",
       " 6: 113.85660874631708,\n",
       " 9: 114.02915140765079,\n",
       " 12: 112.4722332131816,\n",
       " 15: 111.72909661296872,\n",
       " 18: 111.2685466406412,\n",
       " 21: 110.63619634098883,\n",
       " 24: 108.70864199780188,\n",
       " 27: 108.42046284960036,\n",
       " 30: 107.90891439358008}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds=[(i+1)*3 for i in range(10)]\n",
    "avg_rmse={}\n",
    "for fold in folds:\n",
    "    kf=KFold(fold,shuffle=True,random_state=1)\n",
    "    knn=KNeighborsRegressor()\n",
    "    mses=cross_val_score(knn,normalized_listings[features],normalized_listings['price'],scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "    avg_rmse[fold]=np.mean((abs(mses))**(1/2))\n",
    "\n",
    "avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
